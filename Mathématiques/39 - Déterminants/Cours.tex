\documentclass[11pt]{article}

\def\chapitre{39}
\def\pagetitle{Déterminants.}

\input{/home/theo/MP2I/setup.tex}

\DeclareMathOperator*{\Com}{Com}

\begin{document}

\input{/home/theo/MP2I/title.tex}


\section{La théorie dans un \texorpdfstring{$\K$}{Lg}-ev de dimension \texorpdfstring{$n\in\N^*$}{Lg}.}
\subsection{Formes \texorpdfstring{$n$}{Lg}-linéaires alternées.}

\begin{defi}{}{}
    Une forme $n$-linéaire sur $E$ est une fonction $f:E^n\to\K$ telle que 
    \begin{equation*}
        \forall j\in\lb1,n\rb, ~ \forall (a_1,...,a_{j-1},a_{j+1}...,a_n)\in E^{n-1}, ~ x\mapsto f(a_1,...,a_{j-1},x,a_{j+1},...,a_n) \quad \nt{est linéaire.}
    \end{equation*}
\end{defi}

\begin{prop}{}{}
    Soit $f:E^n\to\K$ $n$-linéaire.
    \begin{enumerate}[topsep=0pt,itemsep=-0.9 ex]
        \item $\forall(x_1,...,x_n)\in E^n, ~ \forall \l \in \K, ~ f(\l x_1, ... , \l x_n) = \l^nf(x_1,...,x_n)$.
        \item Soit $(x_1,...,x_n)\in E^n$ tel que l'un des $x_i$ est nul, alors $f(x_1,...,x_n)=0$.
    \end{enumerate}
    \tcblower
    \boxed{1.} $\l$ est factorisé $n$ fois par $n$-linéarité.\\
    \boxed{2.} $f(x_1,...,0_E,...,x_n)=f(x_1,...,0_\K\cdot0_E,...,x_n)=0_\K f(x_1,...,x_n)=0$.
\end{prop}

\begin{defi}{}{}
    Soit $f:E^n\to\K$ $n$-linéaire. On dit que $f$ est alternée si elle s'annule sur tous les $n$-uplets contenant deux vecteurs égaux.
\end{defi}

\begin{prop}{}{}
    Soit $f:E^n\to\K$ une forme $n$-linéaire alternée $(n\geq2)$ et $(x_1,...,x_n)\in E^n$.
    \begin{enumerate}[topsep=0pt,itemsep=-0.9 ex]
        \item On ne change pas la valeur prise par $f$ sur $(x_1,...,x_n)$ en ajoutant à l'un des vecteurs une combinaison linéaire des autres.
        \item Si $(x_1,...,x_n)$ est liée, alors $f(x_1,...,x_n)=0$.
        \item \bf{Effet d'une transposition.} Soit $\{i,j\}$ avec $i<j$. On a :
        \begin{equation*}
            f(...,x_{i-1},\boxed{x_j},x_{i+1},...,x_{j-1},\boxed{x_i},x_{j+1},...)=-f(...,x_{i-1}, \boxed{x_i},x_{i+1},...,x_{j-1},\boxed{x_j},x_{j+1},...)
        \end{equation*}
        L'échange de $x_i$ et $x_j$ provoque un changement de signe.
        \item \bf{Effet d'une permutation.} Pour tout $\s\in S_n$,
        \begin{equation*}
            f(x_{\s(1)},...,x_{\s(n)}) = \e(\s)f(x_1,...,x_n)
        \end{equation*}
        Où $\e:S_n\to\{-1,1\}$ la signature de $\s$ l'unique morphisme non trivial de $(S_n,\circ)$ dans $(\{-1,1\},\times)$
    \end{enumerate}
    \tcblower
    \boxed{1.} Soit $j\in\lb1,n\rb$, $(\l_i)_{i\neq j}\in \K^{n-1}$.\\
    On a $f(x_1,...,x_j+\sum\limits_{i\neq j}\l_ix_i,...,x_n)=f(x_1,...,x_n)+\underbrace{\sum_{i\neq j}\l_if(x_1,...,\overbrace{x_i}^{j},...,x_n)}_{=0\nt{ car alternée et deux fois } x_i}$\n
    \boxed{2.} Supposons $(x_1,...,x_n)$ liée, alors $\exists j\in\lb1,n\rb, ~ \exists(\l_i)_{i\neq j} \mid x_j = \sum\limits_{i\neq j}\l_i x_i$.\\
    Alors $f(x_1,...,x_j,...,x_n)\overset{(1)}{=}f(x_1,...,x_j-\sum\limits_{i\neq j}\l_ix_i,...,x_n)=f(x_1,...,0_E,...,x_n)=0_\K$.\n
    \boxed{3.} On a ;
    \begin{align*}
        f(...,x_j,...,x_i,...)&=f(...,x_j+x_i,...,x_i,...)=f(...,\boxed{x_j+x_i},...,x_i-\boxed{(x_j+x_i)},...)\\
        &=f(...,x_j+x_i,...,-x_j,...)=(-1)f(...,x_j+x_i,...,x_j,...)\\&=(-1)f(...,x_i,...,x_j,...)
    \end{align*}
    \boxed{4.} $\exists p\in\N^*, ~ \exists \t_1,...,\t_p$ transpositions $\mid \s=\t_1\circ...\circ\t_p$. Alors :
    \begin{align*}
        f(x_{\s(1)},...,x_{\s(n)})&=f(x_{\t_1\circ...\circ\t_p(1)},...,x_{\t_1\circ...\circ\t_p(n)})\\
        &=(-1)f(x_{\t_2...\t_p(1)},...,x_{\t_2...\t_p(n)}) \quad \nt{et } (-1)=\e(\t_1)\\
        &=\e(\t_1)...\e(\t_p)f(x_1,...,x_n)\\
        &=\e(\s)f(x_1,...,x_n)
    \end{align*}

\end{prop}


\subsection{Déterminant d'une famille de vecteurs dans une base.}

\begin{thm}{}{detcoeff}
    L'ensemble des formes $n$-linéaires alternées sur $E$ est une droite vectorielle.\n
    Si $\B=(e_1,...,e_n)$ est une base de $E$, alors il existe une unique forme $n$-linéaire alternée qui prend la valeur 1 sur $\B$. On l'appelle \bf{déterminant dans la base $\B$} et on note $\det_\B$. On a:
    \begin{equation*}
        \forall (x_1,...,x_n)\in E^n \quad \det\nolimits_\B(x_1,...,x_n)=\sum_{\s\in S_n}\e(\s)\prod_{j=1}^ne^*_{\s(j)}(x_j).
    \end{equation*}
    \tcblower
    \bf{Analyse.} Soit $f:E^n\to\K$ une forme $n$-linéaire alternée. Soit $(x_1,...,x_n)\in E^n$. Alors
    \begin{align*}
        f(x_1,...,x_n)&=f\left(\sum_{i_1=1}^ne_{i_1}^*(x_1)e_{i_1},...,\sum_{i_n=1}^ne_{i_n}^*(x_n)e_{i_n}\right)\\
        &= \sum_{i_1=1}^n...\sum_{i_n=1}^n\prod_{j=1}^ne_{i_j}^*(x_j)f(e_{i_1},...,e_{i_n})\\
        &= \sum_{(i_1,...,i_n)\in\cursive{A}_n(\lb1,n\rb)}\left( \prod_{j=1}^ne_{i_j}^*(x_j) \right)f(e_{i_1},...,e_{i_n})
    \end{align*}
    Où $(i_1,...,i_n)\in\lb1 \mapsto (\s_i(k)\mapsto i_k)$ bijection de $\cursive{A}_n(\lb1,n\rb)\to S_n$.
    \begin{align*}
        f(x_1,...,x_n)&=\sum_{\s\in S_n}\prod_{j=1}^ne_{\s(j)}^*(x_j)f(e_{s(1)},...,e_{s(n)})\\
        &=f(e_1,...,e_n)\sum_{\s\in S_n}\e(\s)\prod_{j=1}^ne_{\s(j)}^*(x_j)
    \end{align*}
    Supposons que $f(e_1,...,e_n)=1$, il reste un unique candidat.\\
    \bf{Synthèse.} Posons $\det_\B:(x_1,...,x_n)\mapsto \sum\limits_{\s\in S_n}\e(\s)\prod\limits_{j=1}e_{\s(j)}^*(x_j)$. Vérifions qu'elle convient.\\
    $\bullet$ Soit $k\in\lb1,n\rb$ et $(x_1,...,x_{k-1},x_{k+1},x_n)\in E^{n-1}$ et $x\in E$.\\
    Alors $\det_\B(x_1,...,x_n)=\sum\limits_{\s\in S_n}\e(\s)\left(\prod\limits_{j\neq k}e^*_{\s(j)}(x_j)\right)e^*_{\s(k)}(x)$ linéaire car combinaison linéaire de linéaires.\n
    $\bullet$ Soit $1\leq k < l \leq n,$ et $(x_1,...,x_n) \mid x_k = x_l$.\\
    Alors $\det_\B(x_1,...,x_n)=\sum_{\s\in S_n}\e(\s)\prod_{j=1}^ne_{\s(j)}^*(x_j)$. Posons $\t=(k~l)$ qui échange $k$ et $l$.\\
    Alors $\det_\B(x_1,...,x_n)=\sum_{\s\in S_n}\e(\s)\prod_{j=1}^ne_{\s(\t(j))}^*(x_j)=\sum_{\phi\in S_n}\e(\phi\t)\prod_{j=1}^ne^*_{\phi(j)}(x_j)$ où $\phi=\s\t$.\\
    Donc $\det_\B(x_1,...,x_n)=-\sum_{\phi\in S_n}\e(\phi)\prod_{j=1}^ne^*_{\phi(j)}(x_j)=-\det_\B(x_1,...,x_n)$.\\
    Donc $\det_\B(x_1,...,x_n)=0$.\n
    $\bullet$ $\det_\B(\B)=\det_\B(e_1,...,e_n)=\sum\limits_{\s\in S_n}\e(\s)\prod\limits_{j=1}^ne_{\s(j)}^*(e_j)=\sum\limits_{\s\in S_n}\e(\s)\prod\limits_{j=1}^n\d_{j,\s(j)}=\e(\id)=1$.
\end{thm}

\begin{corr}{}{}
    Si $f$ est une forme $n$-linéaire alternée et si $\B$ est une base de $E$, alors $\exists \l\in\K\mid f = \l\det_\B$
\end{corr}

\begin{defi}{}{}
    Soit $\B=(e_1,..,e_n)$ base de $E$ et $(x_1,...,x_n)\in E^n$.\\
    Le nombre $\det_\B(x_1,...,x_n)$ est appelé \bf{déterminant dans la base $\B$} de $(x_1,...,x_n)$. 
\end{defi}

\pagebreak

\begin{thm}{Caractérisation des bases.}{8}
    Soit $\B=(e_1,...,e_n)$ une base de $E$ et $(x_1,...,x_n)\in E^n$.
    \begin{equation*}
        (x_1,...,x_n) \nt{ est base de } E \quad \iff \quad \det\nolimits_\B(x_1,...,x_n)\neq 0
    \end{equation*}
    \tcblower
    \fbox{$\la$} Supposons que le déterminant est différent de 0, alors $(x_1,...,x_n)$ libre, c'est une base car $\dim E = n$.\\
    \fbox{$\ra$} Supposons que $\B'=(x_1,...,x_n)$ est base de $E$. Alors $\det_{\B'}$ existe, c'est une forme $n$-linéaire alternée.\\
    Par théorème, $\exists \l \in \K \mid \det_{\B'}=\l\det_\B$. Alors $\det_{\B'}(\B')=\l\det_{\B}(\B')=1$ donc $\det_{\B}(\B')\neq0$.
\end{thm}

\begin{ex}{Interprétation géométrique.}{}
    $\bullet$ Si $E=\R^2$ et $\B$ est la base canonique de $\R^2$, pour $(\v{u_1},\v{u_2})$ un couple de vecteurs, le nombre $\det_\B(\v{u_1}, \v{u_2})$ peut être vu comme l'aire orientée du parallélogramme engendré par $(\v{u_1},\v{u_2})$.\n
    $\bullet$ Si $E=\R^3$ et $\B$ est la base canonique de $\R^3$, pour $(\v{u_1},\v{u_2},\v{u_3})$ un triplet de vecteurs, le nombre $\det_\B(\v{u_1},\v{u_2},\v{u_3})$ peut être vu comme le volume orienté du parallélépipède engendré par $(\v{u_1},\v{u_2},\v{u_3})$.
\end{ex}

\subsection{Déterminant d'un endomorphisme en dimension finie.}

\begin{lemme}{}{}
    Soit $u\in\L(E)$.\\
    Le nombre $\det_\B(u(e_1),...,u(e_n))$ ne dépend pas de la base $\B=(e_1,...,e_n)$ considérée.
    \tcblower
    Soit $f\in\Lambda_n(E)$ une forme $n$-linéaire alternée.\\
    Déformons la à l'aide de $u\in\L(E)~:~(x_1,...,x_n)\mapsto f(u(x_1),...,u(x_n))$ est $n$-linéaire alternée.\\
    Notons-la $\phi_u(f)\in\Lambda_n(E)$. On pose $\phi_u:f\mapsto\phi_u(f)$ de $\Lambda_n(E) \to \Lambda_n(E)$ linéaire, c'est une homothétie.\\
    Alors $\exists \l_u\in\K\mid\phi_u=\l_u\id_{\Lambda_n(E)}$.\\
    On a prouvé que $\exists \l_u\in\K \quad \forall f \in \Lambda_n(E) \quad \forall (x_1,...,x_n)\in E \quad f(u(x_1),...,u(x_n))=\l_u f(x_1,...,x_n)$.\\
    En particulier, $\det_\B(u(x_1),...,u(x_n))=\l_u\det_\B(x_1,...,x_n)$ est vrai pour tous $x_i$.\\
    En particulier, $\det_\B(u_(\B))=\l_u\det_\B(\B)=\l_u$, ne dépend pas de $\B$.
\end{lemme}

\begin{defi}{}{}
    Soi $u\in\L(E)$. On appelle \bf{déterminant} de $u$ et on note $\det(u)$ le nombre
    \begin{equation*}
        \det(u)=\det\nolimits_\B(\B),
    \end{equation*}
    où $\B=(e_1,...,e_n)$ une base quelconque de $E$.
\end{defi}

\begin{prop}{}{}
    Soit $u\in\L(E)$, $\B$ une base de $E$ et $(x_1,...,x_n)\in E^n$. On a
    \begin{equation*}
        \det\nolimits_\B(u(x_1),...,u(x_n))=\det(u)\times\det\nolimits_\B(x_1,...,x_n)
    \end{equation*}
    \tcblower
    L'application $(x_1,...,x_n)\mapsto\det_\B(u(x_1),...u(x_n))$ est $n$-linéaire alternée : elle est dans $\Vect(\det_\B)$.\\
    Il existe donc $\l\in\K\mid\forall(x_1,...,x_n)\in E^n, ~ \det_\B(u(x_1),...,u(x_n))=\l\det_\B(x_1,...,x_n)$.\\
    En particulier, $\det_\B(u(\B))=\l\det_\B(\B)$ donc $\det(u)=\l$.\\
    On a bien $\det_\B(u(x_1),...,u(x_n))=\det(u)\det_\B(x_1,...,x_n)$.
\end{prop}

\begin{prop}{}{13}
    Soit $E$ un $\K$-espace vectoriel de dimension finie.
    \begin{enumerate}[topsep=0pt,itemsep=-0.9 ex]
        \item $\det(\id_E)=1$.
        \item $\forall u \in \L(E), ~ \forall \l \in \K, ~ \det(\l u) = \l^n\det(u)$
        \item $\forall (u,v)\in\L(E)^2, ~ \det(u\circ v)=\det(u)\det(v)$
        \item Pour tout $u\in\L(E)$, $u$ est un automorphisme de $E$ si et seulement si $\det(u)\neq 0$. Alors:
        \begin{equation*}
            \det(u^{-1})=\det(u)^{-1}
        \end{equation*}
    \end{enumerate}
    \bf{Remarque:} Rien à dire sur $\det(u+v)$.
    \tcblower
    Soit $\B=(e_1,...,e_n)$ une base de $E$.\\
    \boxed{1.} $\det(\id_E)=\det_\B(\id(e_1),...,\id(e_n))=\det_\B(\B)=1$.\\
    \boxed{2.} Soit $u\in\L(E)$ et $\l\in\K$, alors $\det(\l u) = \det_\B(\l u(e_1),...,\l u(e_n))=\l^n\det_\B(u(e_1),...,u(e_n))=\l^n\det(u)$.\\
    \boxed{3.} Soient $u,v\in\L(E)$.\\
    Alors: $\det(u\circ v) = \det_\B(u(v(e_1)),...,u(v(e_n)))=\det(u)\det(v(e_1),...,v(e_n))=\det(u)\det(v)\cancelto{1}{\det_\B(B)}$.\\
    \boxed{4.} Soit $u\in\L(E)$. $u$ est bijectif ssi l'image de $\B$ par $u$ est une base ssi son déterminant dans $B$ est non nul (\ref{thm:8}).
    Alors pour un automorphisme $u$, on a $u\circ u^{-1}=\id_E$ et $\det(u\circ u^{-1})=\det(\id_E)=1$ donc $\det(u^{-1})=\det(u)^{-1}$. 
\end{prop}

\begin{corr}{}{}
    Si $E$ est de dimension finie, $\det$ induit un morphisme de groupes entre $GL(E)$ et $\K^*$.
\end{corr}

\begin{ex}{Déterminant d'une symétrie vectorielle.}{}
    Que dire de $\det(s)$ si $s$ est une symétrie vectorielle de $E$ ?
    \tcblower
    Soit $s\in\L(E)$ une symétrie vectorielle.\\
    Alors $s^2=\id_E$ donc $\det(s^2)=\det(\id_E)=1$.\\
    Alors $\det(s)^2=1$ donc $\det(s)=\pm1$.\n
    On sait que $E=\Ker(s-\id_E)\oplus\Ker(s+\id_E)$.\\
    Prenons une base adaptée à ces deux supplémentaires.\\
    Notons $p=\dim~\Ker(s-\id_E)$ et prenons $(e_1,...,e_p)$ une de ses bases, et $(e_{p+1},...,e_n)$ base de $\Ker(s+\id_E)$.\n
    Notons $B=(e_1,...,e_p,...e_n)$. Alors :
    \begin{align*}
        \det(s)&=\det\nolimits_{\B}(s(e_1),...,s(e_p),...,s(e_n))
        =\det\nolimits_{\B}(e_1,...,e_p,-e_{p+1},...,-e_n)\\
        &=(-1)^{n-p}\det\nolimits_{\B}(\B)
        =(-1)^{n-p}.
    \end{align*}
\end{ex}

\subsection{Déterminant d'une matrice carrée.}

\begin{defi}{}{}
    Soit $A\in M_n(\K)$, on appelle \bf{déterminant} de $A$, et on note $\det(A)$ le nombre
    \begin{equation*}
        \det(A)=\det\nolimits_{\B_c}(C_1,...,C_1).
    \end{equation*}
    où $\B_c$ est la base canonique de $M_{n,1}(\K)$ et $C_1,...,C_n$ les colonnes de $A$.\n
    Autrement dit, $\det(A)$ est le déterminant de l'endomorphisme canoniquement associé à A.
\end{defi}

\begin{nota}{}{}
    Si $A=(a_{i,j})_{1\leq i,j \leq n}$, le déterminant de $A$ est aussi noté
    \begin{equation*}
        \begin{vmatrix}
            a_{1,1} & ... & a_{1,n} \\
            \vdots & \ddots & \vdots \\
            a_{n,1} & ... & a_{n,n}
        \end{vmatrix}
    \end{equation*}
\end{nota}

\begin{thm}{}{}
    \begin{enumerate}[topsep=0pt,itemsep=-0.9 ex]
        \item $\det(I_n)=1$.
        \item $\forall A \in M_n(\K), ~ \forall \l\in\K, ~ \det(\l A) = \l^n\det(A)$.
        \item $\forall (A,B) \in M_n(\K)^2 ~ \det(AB)=\det(A)\det(B)$.
        \item Pour tout $A\in M_n(\K)$, $A$ est inversible ssi $\det(A)\neq 0$, alors:
        \begin{equation*}
            \det(A^{-1})=(\det(A))^{-1}.
        \end{equation*}
    \end{enumerate}
    \tcblower
    C'est juste le théorème \ref{prop:13} appliqué aux endomorphismes canoniquement associés.
\end{thm}

\begin{corr}{}{}
    L'application $\det$ induit un morphisme de groupes entre $GL_n(\K)$ et $\K^*$.
\end{corr}

\begin{prop}{}{}
    Soit $A=(a_{i,j})$ une matrice carrée d'ordre $n\geq1$.
    \begin{equation*}
        \det(A)=\sum_{\s\in S_n}\e(\s)a_{\s(1),1}...a_{\s(n),n}.
    \end{equation*}
    \bf{Remarque:} On appliquera très peu cette formule.
    \tcblower
    Notons $(E_1,...,E_n)$ la base canonique de $M_{n,1}(\K)$ et $(C_1,...,C_n)$ les colonnes de $A$. 
    \begin{equation*}
        \det(A)=\det\nolimits_{\B_c}(C_1,...,C_n)=\sum_{\s\in S_n}\e(\s)\prod_{j=1}^nE^*_{\s(j)}(C_j)=\sum_{\s\in S_n}\e(\s)\prod_{j=1}^na_{\s(j),j}.
    \end{equation*}
\end{prop}

\begin{app}{}{}
    Soit $A=(a_{i,j})\in M_n(\Z)$.\\
    La formule précédente nous donne que $\det(A)$ est une somme de produits d'entiers:
    \begin{equation*}
        A\in M_n(\Z) \ra \det(A)\in \Z.
    \end{equation*}
\end{app}

\begin{ex}{Cohérence avec la définition en taille 2.}{}
    Retrouver à l'aide de la formule précédente l'expression connue pour le déterminant d'une matrice de taille 2:
    \begin{equation*}
        \begin{vmatrix}
            a & b \\
            c & d
        \end{vmatrix}=ad-bc.
    \end{equation*}
    \tcblower
    On a $S_2=\{\id, \t\}$ où $\t=(1~2)$. Alors:
    \begin{align*}
        \det(A)&=\e(\id)a_{\id(1),1}a_{\id(2),2} + \e(\t)a_{\t(1),1}a_{\t(2),2}\\
        &=a_{1,1}a_{2,2}-a_{2,1}a_{1,2}=ad-cb.
    \end{align*}
\end{ex}

\begin{ex}{}{}
    Soient $(X_{i,j})_{1\leq i,j \leq n}$ une famille de variables aléatoires indépendantes sur un espace probabilisé fini $(\O,P)$.\\
    On note $M=(X_{i,j})_{1\leq i,j \leq n}$ une matrice aléatoire. Démontrer que
    \begin{equation*}
        E\left[ \det((X_{i,j}))_{1\leq i,j \leq n} \right]=\det\left[ (E(X_{i,j}))_{1\leq i,j \leq n} \right]
    \end{equation*}
    \tcblower
    On a:
    \begin{align*}
        E\left[ \det((X_{i,j}))\right]&=E\left[ \sum_{\s\in S_n}\e(\s)\prod_{j=1}^nX_{\s(j),j} \right]\\
        &=\sum_{\s\in S_n}\e(\s)E\left[ \prod_{j=1}^nX_{\s(j),j} \right] \quad \nt{linéarité.}\\
        &=\sum_{\s\in S_n}\e(\s)\prod_{j=1}^nE\left[ X_{\s(j),j} \right] \quad \nt{indépendance.}\\
        &=\det(E(X_{i,j}))_{1\leq i,j \leq n}.
    \end{align*}
\end{ex}

\begin{thm}{}{}
    \begin{equation*}
        \forall A \in M_n(\K), ~ \det(A^\top)=\det(A).
    \end{equation*}
    \tcblower
    Soit $A=(a_{i,j})\in M_n(\K)$. Alors:
    \begin{align*}
        \det(A^\top) &= \sum_{\s\in S_n}\e(\s)\prod_{j=1}^n\left[A^\top\right]_{\s(j),j}\\
        &= \sum_{\s\in S_n}\e(\s)\prod_{j=1}^n[A]_{j,\s(j)}\\
        &= \sum_{\s\in S_n}\e(\s)\prod_{k=1}^na_{\s^{-1}(k),k} \quad \nt{(k := $\s(j)$)}\\
        &= \sum_{\s\in S_n}\e(\s^{-1})\prod_{k=1}^na_{\s^{-1}(k),k} \quad \nt{($\e(\s^{-1})=\e(\s)$)}\\
        &= \sum_{\phi \in S_n}\e(\phi)\prod_{k=1}^,a_{\phi(k),k} \quad \nt{($\phi:=\s^{-1}$)}\\
        &= \det(A).
    \end{align*}

\end{thm}

\begin{corr}{}{}
    Soit $A\in M_n(\K)$ de lignes $L_1,...,L_n$.
    \begin{equation*}
        \det(A)=\det\nolimits_{\B_c}(L_1,...,L_n)
    \end{equation*}
    où $\B_c$ est la base canonique de $M_{1,n}(\K)$.
\end{corr}

\pagebreak

\begin{prop}{}{}
    Soit $u\in\L(E)$ et $\B=(x_1,...,x_n)$ une base de $E$. On a
    \begin{equation*}
        \det(\nt{Mat}_\B(u))=\det(u)
    \end{equation*}
    \tcblower
    Notons $(a_{i,j})$ les coefficients de $\nt{Mat}_\B(u)$.
    \begin{align*}
        \det(\nt{Mat}_\B(u))&=\sum_{\s\in S_n}\e(\s)\prod_{j=1}^na_{\s(j),j}=\sum_{\s\in S_n}\e(\s)\prod_{j=1}^nx^*_{\s(j)}(u(x_j))=\det\nolimits_\B(u)=\det(u).
    \end{align*}
\end{prop}

\begin{corr}{}{}
    Deux matrices semblables ont même déterminant.
    \tcblower
    Soient $A,B\in M_n(\K)$ semblables : $\exists P\in GL_n(\K)~B=P^{-1}AP$.
    \begin{align*}
        \det(B)&=\det(P^{-1}AP)=\det(P^{-1})\det(A)\det(P)=\det(P)^{-1}\det(P)\det(A)=\det(A).
    \end{align*}
    \bf{Preuve :}\n
    Notons $f\in\L(\K^n)$ canoniquement associé à $A$ : $\Mat_\B(f)=A$ avec $\B$ base canonique de $\K^n$.\\
    Notons $\cursive{C}$ la base des colonnes de $P$. D'après le changement de base, $B=\Mat_{\cursive{C}}(f)$.\\
    Donc d'après la proposition précédente:
    \begin{equation*}
        \det(A) = \det(f) = \det(B).
    \end{equation*}
\end{corr}
 
\section{La pratique.}

\subsection{Échelonner.}

\begin{prop}{Effet des opérations de pivot sur les colonnes.}{}
    Soit $A\in M_n(\K)$. On note $(C_j,~j\in\lb1,n\rb)$ ses colonnes. Soit $\m{O}$ une opération élémentaire sur les colonnes, transformant $A$ en $B$:
    \begin{equation*}
        A\underset{\m{O}}{\sim}B.
    \end{equation*}
    \begin{enumerate}[topsep=0pt,itemsep=-0.9 ex]
        \item Si $\m{O}$ est du type $C_i \leftrightarrow C_j$, alors $\det(B)=-\det(A)$,
        \item Si $\m{O}$ est du type $C_i \leftarrow \l C_i$, alors $\det(B)=\l \det(A)$,
        \item Si $\m{O}$ est du type $C_i \leftarrow C_i+\l C_j$, alors $\det(B)=\det(A)$.
    \end{enumerate}\vspace{0.25cm}
    Le déterminant étant invariant par transposition, tout reste vrai pour des opérations élémentaires sur les lignes.
    \tcblower
    Notons $\B_c$ la base canonique de $\K^n$.\\
    On sait que $\det(A)=\det_{\B_c}(C_1,...,C_n)$ qui est $n$-linéaire alternée.
\end{prop}

\begin{prop}{}{}
    Le déterminant d'une matrice triangulaire est le produit de ses coefficients diagonaux.\\
    Par exemple, pour une matrice triangulaire supérieure,
    \begin{equation*}
        \begin{vmatrix}
            a_{1} & a_{1,2} & ... & a_{1,n} \\
            0 & a_{2} & \ddots & \vdots \\
            \vdots & \ddots & \ddots & * \\
            0 & ... & 0 & a_{n}
        \end{vmatrix}=\prod_{j=1}^na_j
    \end{equation*}
    \tcblower
    Soit $A$ une matrice triangulaire.
    \begin{equation*}
        \det(A)=\sum_{\s\in S_n}\e(\s)\prod_{j=1}^na_{\s(j),j}
    \end{equation*}
    Le produit vaut $0$ sauf si $\s=\id$, il ne reste que $\prod_{j=1}^na_{j,j}$.\n
    \bf{Preuve :}\n
    $\bullet$ Si l'un des coefficients diagonaux est nul, $A$ n'est pas inversible donc le déterminant vaut 0. Cohérent.\\
    $\bullet$ Sinon, $\forall j \in \lb 1,n \rb ~ a_j \neq 0$. Alors :
    \begin{equation*}
        \begin{vmatrix}
            a_{1} & a_{1,2} & ... & a_{1,n} \\
            0 & a_{2} & \ddots & \vdots \\
            \vdots & \ddots & \ddots & * \\
            0 & ... & 0 & a_{n}
        \end{vmatrix}
        =
        \begin{vmatrix}
            a_{1} & 0 & ... & 0 \\
            0 & a_{2} & a_{2,3}\dots & \vdots \\
            \vdots & \ddots & \ddots & * \\
            0 & ... & 0 & a_{n}
        \end{vmatrix}
    \end{equation*}
    L'opération est $C_2 \gets C_2 - \frac{a_{1,2}}{a_1}C_1$, ..., $C_n \gets C_n - \frac{a_{1,n}}{a_1}C_1$.\\
    En itérant, on se ramène à une matrice diagonale de colonnes $(C'_1,...,C'_n)$.\\
    Par linéarité, son déterminant est $a_1...a_n\cdot \det(I_n)=\prod_{j=1}^na_j$.\\
    Par transitivité, c'est aussi le déterminant de $A$.

\end{prop}

\begin{ex}{}{}
    Calculer$\quad \begin{vmatrix}
        5 & 6 & -2 \\
        10 & 6 & -4 \\
        15 & 6 & -2
    \end{vmatrix}
    \quad \nt{et} \quad
    \begin{vmatrix}
        1 & 2 & 3 \\
        4 & 5 & 6 \\
        7 & 8 & 9
    \end{vmatrix}$.
    \tcblower
    On a:
    \begin{equation*}
        \begin{vmatrix}
            5 & 6 & -2 \\
            10 & 6 & -4 \\
            15 & 6 & -2
        \end{vmatrix}
        =5\cdot6\cdot(-2)\begin{vmatrix}
            1&1&1\\
            2&1&2\\
            3&1&1
        \end{vmatrix}
        =-60\begin{vmatrix}
            1&1&1\\
            0&-1&0\\
            0&-2&-2
        \end{vmatrix}
        =-60\begin{vmatrix}
            1&1&1\\
            0&-1&0\\
            0&0&-2
        \end{vmatrix}=-120.
    \end{equation*}
    L'autre est non-inversible donc de déterminant 0 car de rang $2<3$. 
\end{ex}

\begin{ex}{}{}
    Soit $a\in\K$. Calculer le déterminant de taille $n$ ci-dessous.
    \begin{equation*}
        D:=\begin{vmatrix}
            a&1&&(1)\\
            1&\ddots&\ddots&\\
            &\ddots&\ddots&1\\
            (1)&&1&a
        \end{vmatrix}
    \end{equation*}
    \bf{Indication:} la somme des éléments de chaque colonne (ou ligne) est toujours la même.
    \tcblower
    On a:
    \begin{equation*}
        D=\begin{vmatrix}
            a+n-1&1&...&...&1\\
            a+n-1&a&&&\\
            \vdots&1&\ddots&&\\
            \vdots&\vdots&&\ddots&\\
            a+n-1&1&...&1&a
        \end{vmatrix}
        =(a+n-1)\begin{vmatrix}
            1&1&...&...&1\\
            1&a&1&...&1\\
            \vdots&1&\ddots&\ddots&\vdots\\
            \vdots&\vdots&&\ddots&1\\
            1&1&...&1&a
        \end{vmatrix}
        =(a+n-1)\begin{vmatrix}
            1&0&...&...&0\\
            \vdots&a-1&0&...&0\\
            \vdots&0&\ddots&\ddots&\vdots\\
            \vdots&\vdots&&\ddots&0\\
            1&0&...&0&a-1
        \end{vmatrix}
    \end{equation*}
    Opérations : $c_1\gets c_1+\sum_{j=2}^nc_j$, puis $\forall i\geq2, ~ c_i \gets c_i - c_1$.\\
    Donc $D=(a+n-1)(a-1)^{n-1}$.\n
    Bonus : La matrice est inversible ssi $a\in\K\setminus\{1,1-n\}$.
\end{ex}

\subsection{Développer selon une colonne ou une ligne.}

\begin{nota}{}{}
    Soit $A=(a_{i,j})_{1\leq i,j\leq n}\in M_n(\K)$ et $(i,j)\in\lb1,n\rb^2$.\\
    On appelle mineur à la position $(i,j)$, noté $\D_{i,j}$ le déterminant de $A$ en supprimant la ligne $i$ et la colonne $j$.
\end{nota}

\begin{lemme}{}{}
    Soit $n\in\N\setminus\{0,1\}$ et $a_2,...,a_n$ dans $\K$. Alors,
    \begin{equation*}
        \forall A \in M_{n-1}(\K), ~ \begin{vmatrix}
            1&0&...&0\\\
            a_2&&&\\
            \vdots&&A&\\
            a_n&&&
        \end{vmatrix}_n
        =\begin{vmatrix}
            &&\\
            &A&\\
            &&
        \end{vmatrix}_{n-1}
    \end{equation*}
    \tcblower
    Posons 
    \begin{equation*}
        \Psi:\begin{cases}M_{n-1}(\K) &\to \quad \K\\
        A &\mapsto \quad \begin{vmatrix}
            1&0&...&0\\\
            a_2&&&\\
            \vdots&&A&\\
            a_n&&&
            \end{vmatrix}_n
        \end{cases}
    \end{equation*}
    On peut montrer que $\Psi$ est $n$-linéaire alternée, puis calculer l'image de la base canonique de $M_{n-1,1}$.
\end{lemme}

\pagebreak

\begin{thm}{}{}
    Soit $A=(a_{i,j})\in M_n(\K)$. On a, en développant selon la colonne $j$ ou la ligne $i$:
    \begin{equation*}
        \forall j\in\lb1,n\rb, \quad \det(A)=\sum_{i=1}^na_{i,j}(-1)^{i+j}\D_{i,j} \quad \nt{et} \quad \forall i\in\lb1,n\rb, \quad \det(A)=\sum_{j=1}^na_{i,j}(-1)^{i+j}\D_{i,j}
    \end{equation*}
    \tcblower
    Pour $i\in\lb1,n\rb$, on a:
    \begin{align*}
        \det(A)=\begin{vmatrix}
            a_{1,1} & ... & a_{1,n} \\
            \vdots &  & \vdots \\
            a_{i,1} & ...& a_{i,n}\\
            \vdots &  & \vdots \\
            a_{n,1} & ... & a_{n,n}
        \end{vmatrix}
        &=\sum_{j=1}^na_{i,j}\begin{vmatrix}
            a_{1,1}&...&...&a_{1,j}&...&...&a_{1,n}\\
            \vdots&&&&&&\vdots\\
            0&...&0&1&0&...&0\\
            \vdots&&&&&&\vdots\\
            a_{n,1}&...&...&a_{n,j}&...&...&a_{n,n}
        \end{vmatrix}\\[0.4cm]
        &=\sum_{j=1}^na_{i,j}\begin{vmatrix}
            0&...&0&1&0&...&0\\
            a_1,1&...&&&&...&a_{1,n}\\
            \vdots&&&&&&\vdots\\
            a_{n,1}&...&...&...&...&...&a_{n,n}
        \end{vmatrix}(-1)^n\\[0.4cm]
        &=\sum_{j=1}^na_{i,j}(-1)^{i-1}(-1)^{j-1}\begin{vmatrix}
            1&0&...&0\\
            a_{1,j}&a_{1,1}&...&a_{1,n}\\
            \vdots&\vdots&&\vdots\\
            a_{n,j}&a_{n,1}&...&a_{n,n}
        \end{vmatrix}\n
        &=\sum_{j=1}^na_{i,j}(-1)^{i+1}\D_{i,j}.
    \end{align*}
    À l'étape 1, on échange la ligne $i$ avec la ligne $i-1$ successivement jusqu'à 1.\\
    À l'étape 2, on échange la colonne $j$ avec la colonne $j-1$ successivement jusqu'à 1.\\
    On se retrouve avec la matrice de départ où la ligne $i$ est à la position $1$ et la colonne $j$ à la position $1$.\\
    On peut alors utiliser le lemme.
\end{thm}

\begin{app}{}{}
    \begin{align*}
        &\begin{vmatrix}
            a&b&c\\
            d&e&f\\
            g&h&i
        \end{vmatrix} = \sum_{j=1}^3(-1)^{1+j}[A]_{1,j}\D_{1,j}=+a\begin{vmatrix}e&f\\h&i\end{vmatrix}-b\begin{vmatrix}d&f\\g&i\end{vmatrix}+c\begin{vmatrix}d&e\\g&h\end{vmatrix} \nt{selon } L_1.\\
        &\begin{vmatrix}
            a&b&c\\
            d&e&f\\
            g&h&i
        \end{vmatrix} = -b\begin{vmatrix}d&f\\g&i\end{vmatrix}+e\begin{vmatrix}a&c\\g&i\end{vmatrix}-h\begin{vmatrix}a&c\\d&f\end{vmatrix} \nt{selon } C_2.
    \end{align*}
\end{app}

\begin{ex}{}{}
    Soit $x$ un réel. On note $D(x)=\begin{vmatrix}
        (1+x)^2&(2+x)^2&(3+x)^2&(4+x)^2\\
        2^2&3^2&4^2&5^2\\
        3^2&4^2&5^2&6^2\\
        4^2&5^2&6^2&7^2
    \end{vmatrix}$\\
    a) Justifier que $D:x\mapsto D(x)$ est une fonction polynomiale de degré au plus 2.\\
    b) En déduire la valeur de $D(x)$ pour tout $x$.
    \tcblower
    a) On développe selon la première ligne.
    \begin{equation*}
        D(x)=(1+x)^2\D_{1,1}-(2+x)^2\D_{1,2}+(3+x)^2\D_{1,3}-(4+x)^2\D_{1,4}.
    \end{equation*}
    C'est une combinaison linéaire de polynomes de degrés inférieurs à 2, $D$ est bien de degré inférieur à 2.\n
    b) On remarque que $D(1)=0$, car alors $L_1=L_2$, $D(2)=0$ car alors $L_1=L_3$ et $D(3)=0$ car alors $L_1=L_4$.\\
    C'est un polynôme a trois racines distinctes, donc $D$ est le polynôme nul (trop de racines).
\end{ex}

\pagebreak

\begin{ex}{}{}
    Soit $n\in\N^*$ et $a,b\in\K$. Soit la matrice bidiagonale:
    \begin{equation*}
        \begin{pmatrix}
            a&&&b\\
            &\ddots&\iddots&\\
            &\iddots&\ddots&\\
            b&&&a
        \end{pmatrix}\in M_{2n}(\C).
    \end{equation*}
    Calculer son déterminant $D_n$ en établissant une realtion de récurrence satisfaite par $(D_n)$.
    \tcblower
    Notons $\D_n$ le déterminant de taille $2n$.
    \begin{align*}
        \D_n&=a\begin{vmatrix}
            a&&&b&0\\
            0&a&\iddots&&\\
            &\iddots&\ddots&&\\
            b&&&\ddots&\\
            0&&&&a
        \end{vmatrix}-b\begin{vmatrix}
            0&a&&&b\\
            0&0&\ddots&b&0\\
            &&\iddots&\ddots&\\
            &\iddots&&&a\\
            b&&&&0
        \end{vmatrix}\\
        &=a^2\begin{vmatrix}
            a&&&b\\
            &\ddots&\iddots&\\
            &\iddots&\ddots&\\
            b&&&a
        \end{vmatrix}-b^2\begin{vmatrix}
            a&&&b\\
            &\ddots&\iddots&\\
            &\iddots&\ddots&\\
            b&&&a
        \end{vmatrix} \quad \nt{selon }L_{2n-1} \nt{ et } C_1\n
        &=(a^2-b^2)\D_{n-1}
    \end{align*}
    Conclusion : $\forall n \in \N^*, ~ \D_n = (a^2-b^2)^{n-1}\D_1$ où $\D_1=\begin{vmatrix}
        a&b\\
        b&a
    \end{vmatrix}=a^2-b^2$.\\
    Alors $\D_n=(a^2-b^2)^n$ pour tout $n\in\N^*$.\n
    Donc inversible quand $a\neq\pm b$.
\end{ex}

\begin{thm}{Déterminant de Vandermonde.}{}
    Soient $a_1,...,a_n$ $n$ nombres réels ou complexes.
    \begin{equation*}
        \begin{vmatrix}
            1&a_1&a_1^2&...&a_1^{n-1}\\
            1&a_2&a_2^2&...&a_2^{n-1}\\
            \vdots&\vdots&\vdots&&\vdots\\
            1&a_n&a_n^2&...&a_n^{n-1}
        \end{vmatrix}
        = \prod_{1\leq i < j \leq n}(a_j-a_i)
    \end{equation*}
    \tcblower
    On va factoriser les $a_i-a_1$ de droite à gauche: $c_i \gets c_i - a_1 c_{i-1}$.\\
    Notation: $V(a_1,...,a_n)$ le déterminant à calculer.
    \begin{equation*}
        V(a_1,...,a_n)=\begin{vmatrix}
            1&0&\dots&0&0\\
            1&a_2-a_1&\dots&a_2^{n-3}(a_2-a_1)&a_2^{n-2}(a_2-a_1)\\
            \vdots&\vdots&&\vdots&\vdots\\
            1&a_n-a_1&\dots&a_n^{n-3}(a_n-a_1)&a_n^{n-2}(a_n-a_1)
        \end{vmatrix}
    \end{equation*}
    On développe selon la première ligne.
    \begin{align*}
        V(a_1,...,a_n)&=(-1)^{1+1}\begin{vmatrix}
            a_2-a_1&...&a_2^{n-2}(a_2-a_1)\\
            \vdots&&\vdots\\
            a_n-a_1&...&a_n^{n-2}(a_n-a_1)
        \end{vmatrix}\\
        &=(a_2-a_1)...(a_n-a_1)\begin{vmatrix}
            1&a_2&...&a_2^{n-2}\\
            \vdots&\vdots&&\vdots\\
            1&a_n&...&a_n^{n-2}
        \end{vmatrix}\\
        &=\prod_{j=2}^n(a_j-a_1)V(a_2,...,a_n)\\
        &=\prod_{j=2}^n(a_j-a_1)\prod_{j=3}^n(a_j-a_2)V(a_3,...,a_n)\\
        &=\prod_{i<j}(a_j-a_i)V(a_n)\\
        &=\prod_{i<j}(a_j-a_i)
    \end{align*}
    Voir aussi l'exercice 39.9 du TD.
\end{thm}

\pagebreak

\begin{ex}{}{}
    Deux exemples de problèmes se ramenant à des déterminants de Vandermonde:\\
    1. L'interpolation de Lagrange.\\
    2. Le problème des moments pour des variables aléatoires d'image finie.
    \tcblower
    Soit $(\O,P)$ un espace probabilisé fini et $X:\O\to\K$, $X(\O)$ est fini, on note $n=|X(\O)|$.\\
    Soient $x_1,...,x_n$ ses éléments deux-à-deux distincts.\\
    Notation: pour $k\in\lb0,n-1\rb,$ $m_k=E(X^k)$, pour $i\in\lb1,n\rb,$ $p_i=P(X=x_i)$.\\
    Soit $k\in\lb0,n-1\rb$, d'après la formule du transfert:
    \begin{equation*}
        m_k=\sum_{i=1}^np_ix_i^k
    \end{equation*}
    Le système linéaire:
    \begin{equation*}
        \begin{pmatrix}
            m_0\\
            m_1\\
            \vdots\\
            m_{n-1}
        \end{pmatrix}=\begin{pmatrix}
            1&1&...&1\\
            x_1&x_2&...&x_n\\
            \vdots&\vdots&&\vdots\\
            x_1^{n-1}&x_2^{n-1}&...&x_n^{n-1}
        \end{pmatrix}\begin{pmatrix}
            p_1\\
            p_2\\
            \vdots\\
            p_n
        \end{pmatrix}=V^{\top}\begin{pmatrix}
            p_1\\
            \vdots\\
            p_n
        \end{pmatrix}
    \end{equation*}
    On sait que $\det(V^{\top})=\det(V)=\prod_{i<j}(x_j-x_i)\neq0$ car les $x_i$ sont deux-à-deux différents.\\
    Donc $V^\top$ est inversible:
    \begin{equation*}
        \begin{pmatrix}
            p_1\\
            \vdots\\
            p_n
        \end{pmatrix}=(V^\top)^{-1}\begin{pmatrix}
            m_0\\
            \vdots\\
            m_{n-1}
        \end{pmatrix}
    \end{equation*}  
    On voit bien que connaître les $m_k$ permet de retrouver les $p_i$.
\end{ex}

\subsection{Complément théorique : la comatrice.}

\begin{defi}{}{}
    Soit $A=(a_{i,j})\in M_n(\K)$ et $(i,j)\in\lb1,n\rb^2$.\\
    Le réel $A_{i,j}=(-1)^{i+j}\D_{i,j}$ est appelé \bf{cofacteur} de $a_{i,j}$ dans $A$.\\
    La matrice $(A_{i,j})_{1\leq i,j \leq n}$ est appelée \bf{comatrice} de $A$ et notée $\Com(A)$.
\end{defi}

\begin{prop}{}{}
    \begin{equation*}
        \forall A \in M_n(\K), ~ A\cdot(\Com(A))^\top = (\Com(A))^\top\cdot A=\det(A)I_n.
    \end{equation*}
    En particulier, si $A$ est inversible, alors $A^{-1}=\frac{1}{\det(A)}(\Com(A))^\top$.
    \tcblower
    Soient $i,j\in\lb1,n\rb$. Alors:
    \begin{align*}
        \left[ A(\Com(A))^\top \right]_{i,j}&=\sum_{k=1}^na_{i,k}\left[\Com(A)^\top\right]_{k,j}\\
        &=\sum_{k=1}^na_{i,k}[\Com(A)]_{j,k}\\
        &=\sum_{k=1}^na_{i,k}(-1)^{j+k}\D_{j,k}
    \end{align*}
    Si $i=j$, on reconnaît le développement selon la $i^{\nt{ème}}$ ligne de $\det(A)$.\\
    Si $i\neq j$, on reconnaît le développement selon la $j^{\nt{ème}}$ ligne de la matrice $\tilde{A}$ obtenue en remplaçant la $j^{\nt{ème}}$ ligne de $A$ par la $i^{\nt{ème}}$ ligne de $A$. Donc le déterminant est nul (argument de rang).\\
    Bilan: $\left[ A(\Com(A))^\top \right]_{i,j}=\begin{cases}\det(A)~\nt{si}~i=j.\\0~\nt{sinon.}\end{cases}$\\
    Donc $A(\Com(A))^\top=\det(A)I_n$.
\end{prop}

\begin{ex}{}{}
    Si $A=\begin{pmatrix}
        a&c\\
        b&d
    \end{pmatrix}$, on retrouve que $A^{-1}=\frac{1}{ad-bc}\begin{pmatrix}
        d&-c\\
        -b&a
    \end{pmatrix}$
    \tcblower
    On a:
    \begin{equation*}
        \Com(A)=\begin{pmatrix}
            (-1)^{1+1}\D_{1,1}&(-1)^{1+2}\D_{1,2}\\
            (-1)^{2+1}\D_{2,1}&(-1)^{2+2}\D_{2,2}
        \end{pmatrix}=\begin{pmatrix}
            d&-b\\
            -c&a
        \end{pmatrix}
    \end{equation*}
    Alors
    \begin{equation*}
        A^{-1}=\frac{1}{\det(A)}(\Com(A))^\top=\frac{1}{ad-bc}\begin{pmatrix}
            d&-c\\
            -b&a
        \end{pmatrix}
    \end{equation*}
\end{ex}

\begin{ex}{Inverse à coefficients entiers.}{}
    1. Si $A\in M_n(\Z)$, justifier que $\det(A)\in\Z$.\\
    2. Soit $A\in GL_n(\R)\cap M_n(\Z)$. Montrer que 
    \begin{equation*}
        A^{-1}\in M_n(\Z)\iff \det(A)=\pm1.
    \end{equation*}
    \tcblower
    1. C'est vrai d'après \ref{thm:detcoeff}, somme et produit d'entiers.\\
    2. \fbox{$\ra$} Supposons $A^{-1}\in M_n(\Z)$, on a $AA^{-1}=I_n$ donc $\det(A)\det(A^{-1})=1$.\\
    Donc $\det(A)$ est un entier inversible dans $\Z$, donc $\det(A)\in\{\pm1\}$\n
    \fbox{$\la$} Supposons $\det(A)=\pm1$. On a:
    \begin{equation*}
        A^{-1}=\frac{1}{\det(A)}\Com(A)^\top=\pm\Com(A)^\top
    \end{equation*}
    Or, $\Com(A)=((-1)^{i+j}\D_{i,j})$ or les $\D_{i,j}$ sont des entiers car déterminants de matrices de $M_n(\Z)$.\\
    Donc $A^{-1}=\pm\Com(A)^\top\in M_n(\Z)$
\end{ex}

\end{document}